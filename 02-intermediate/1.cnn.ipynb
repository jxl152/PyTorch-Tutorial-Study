{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cnn.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMgSZRQkwvnZDSRt0AHFZPK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"q2gCbGH4xSx7","executionInfo":{"status":"ok","timestamp":1658412947930,"user_tz":-120,"elapsed":2690,"user":{"displayName":"Ji Lan","userId":"06508059979673879762"}}},"outputs":[],"source":["import torch \n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms"]},{"cell_type":"markdown","source":["# 1. Hyper-parameters and Dataset"],"metadata":{"id":"Cvc_w8GNt0i8"}},{"cell_type":"code","source":["# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Hyper parameters\n","num_epochs = 5\n","num_classes = 10\n","batch_size = 100\n","learning_rate = 0.001"],"metadata":{"id":"APz8qyJV2GOd","executionInfo":{"status":"ok","timestamp":1658412947931,"user_tz":-120,"elapsed":5,"user":{"displayName":"Ji Lan","userId":"06508059979673879762"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iX5dAKwG2boN","executionInfo":{"status":"ok","timestamp":1658412972542,"user_tz":-120,"elapsed":24615,"user":{"displayName":"Ji Lan","userId":"06508059979673879762"}},"outputId":"8b356b7a-ea17-488a-fb41-db9804df1532"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["data_dir = '/content/drive/My Drive/PyTorch/Github_Series/02-intermediate/'\n","\n","# MNIST dataset\n","train_dataset = torchvision.datasets.MNIST(root=data_dir,\n","                                           train=True, \n","                                           transform=transforms.ToTensor(),\n","                                           download=True)\n","\n","test_dataset = torchvision.datasets.MNIST(root=data_dir,\n","                                          train=False, \n","                                          transform=transforms.ToTensor())\n","\n","# Data loader\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size, \n","                                           shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size, \n","                                          shuffle=False)"],"metadata":{"id":"jbSG1jcC2M-L","executionInfo":{"status":"ok","timestamp":1658412980491,"user_tz":-120,"elapsed":7954,"user":{"displayName":"Ji Lan","userId":"06508059979673879762"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# 2. Modeling and Training\n","\n","**Batch Normalization**\n","1. Accelerate deep network training. [Paper of Batch Normalization.](https://arxiv.org/abs/1502.03167)\n","2. Because the Batch Normalization is done over the C dimension, computing statistics on (N, H, W) slices, itâ€™s common terminology to call this Spatial Batch Normalization.\n","3. A discussion about the [Ordering of batch normalization and activation.](https://stackoverflow.com/questions/39691902/ordering-of-batch-normalization-and-dropout#:~:text=So%20in%20summary%2C%20the%20order%20of%20using%20batch,%28or%20other%20activation%29%20-%3E%20Dropout%20-%3E%20CONV%2FFC%20-%3E), which is also discussed in the paper listed above. \n","\n","**Convolutional layer**\n","1. The formula for computing the output shape is described in [the PyTorch document](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html). After *layer1* and *layer2*, we can compute the output shape of each filter is 7x7. "],"metadata":{"id":"Iqr_VH71xZGb"}},{"cell_type":"code","source":["# Convolutional neural network (two convolutional layers)\n","class ConvNet(nn.Module):\n","\n","  def __init__(self, num_classes=10):\n","    super().__init__()\n","    # Use Sequential to create a small model.\n","    self.layer1 = nn.Sequential(\n","        nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2),\n","        nn.BatchNorm2d(16),\n","        nn.ReLU(),\n","        nn.MaxPool2d(kernel_size=2, stride=2))\n","    self.layer2 = nn.Sequential(\n","        nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n","        nn.BatchNorm2d(32),\n","        nn.ReLU(),\n","        nn.MaxPool2d(kernel_size=2, stride=2))\n","    self.fc = nn.Linear(7*7*32, num_classes)\n","\n","  def forward(self, x):\n","    out = self.layer1(x)\n","    out = self.layer2(out)\n","    out = out.reshape(out.size(0), -1)\n","    out = self.fc(out)\n","    return out"],"metadata":{"id":"hfrmgfU62u2e","executionInfo":{"status":"ok","timestamp":1658412980491,"user_tz":-120,"elapsed":10,"user":{"displayName":"Ji Lan","userId":"06508059979673879762"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["model = ConvNet(num_classes).to(device)\n","\n","# loss and optimizer\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"],"metadata":{"id":"GSxw9cwHMf9Z","executionInfo":{"status":"ok","timestamp":1658412983794,"user_tz":-120,"elapsed":3312,"user":{"displayName":"Ji Lan","userId":"06508059979673879762"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Train the model\n","total_step = len(train_loader)\n","for epoch in range(num_epochs):\n","  for batch_id, (images, labels) in enumerate(train_loader):\n","    # keep model and data on the same device\n","    images = images.to(device)\n","    labels = labels.to(device)\n","\n","    # Feedforward\n","    output = model.forward(images)\n","    loss = loss_fn(output, labels)\n","\n","    # Backward propagation\n","    optimizer.zero_grad() \n","    loss.backward()\n","    optimizer.step()\n","\n","    if (batch_id+1) % 100 == 0:\n","      print('Epoch: [{}/{}], Step: [{}/{}], Loss: {:.4f}'\n","            .format(epoch+1, num_epochs, batch_id+1, total_step, loss.item()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pzMUjOTMl4vi","executionInfo":{"status":"ok","timestamp":1658413021775,"user_tz":-120,"elapsed":37990,"user":{"displayName":"Ji Lan","userId":"06508059979673879762"}},"outputId":"64edb623-ec77-48d3-fbe5-055712e70ad6"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: [1/5], Step: [100/600], Loss: 0.1569\n","Epoch: [1/5], Step: [200/600], Loss: 0.1130\n","Epoch: [1/5], Step: [300/600], Loss: 0.1141\n","Epoch: [1/5], Step: [400/600], Loss: 0.0510\n","Epoch: [1/5], Step: [500/600], Loss: 0.0988\n","Epoch: [1/5], Step: [600/600], Loss: 0.0347\n","Epoch: [2/5], Step: [100/600], Loss: 0.0225\n","Epoch: [2/5], Step: [200/600], Loss: 0.0150\n","Epoch: [2/5], Step: [300/600], Loss: 0.0189\n","Epoch: [2/5], Step: [400/600], Loss: 0.0863\n","Epoch: [2/5], Step: [500/600], Loss: 0.0367\n","Epoch: [2/5], Step: [600/600], Loss: 0.0338\n","Epoch: [3/5], Step: [100/600], Loss: 0.0165\n","Epoch: [3/5], Step: [200/600], Loss: 0.0385\n","Epoch: [3/5], Step: [300/600], Loss: 0.0295\n","Epoch: [3/5], Step: [400/600], Loss: 0.0248\n","Epoch: [3/5], Step: [500/600], Loss: 0.0270\n","Epoch: [3/5], Step: [600/600], Loss: 0.0218\n","Epoch: [4/5], Step: [100/600], Loss: 0.0048\n","Epoch: [4/5], Step: [200/600], Loss: 0.0631\n","Epoch: [4/5], Step: [300/600], Loss: 0.0021\n","Epoch: [4/5], Step: [400/600], Loss: 0.0268\n","Epoch: [4/5], Step: [500/600], Loss: 0.0294\n","Epoch: [4/5], Step: [600/600], Loss: 0.0103\n","Epoch: [5/5], Step: [100/600], Loss: 0.0074\n","Epoch: [5/5], Step: [200/600], Loss: 0.0237\n","Epoch: [5/5], Step: [300/600], Loss: 0.0241\n","Epoch: [5/5], Step: [400/600], Loss: 0.0633\n","Epoch: [5/5], Step: [500/600], Loss: 0.0090\n","Epoch: [5/5], Step: [600/600], Loss: 0.0143\n"]}]},{"cell_type":"markdown","source":["# 3. Test the model"],"metadata":{"id":"MhVmtYwOxebr"}},{"cell_type":"code","source":["# Test the model\n","model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n","with torch.no_grad():\n","  total = 0\n","  correct = 0\n","  for images, labels in test_loader:\n","    images = images.to(device)\n","    labels = labels.to(device)\n","    output = model(images)\n","    _, pred = torch.max(output, dim=1)\n","    total += labels.size(0)\n","    correct += (labels == pred).sum()\n","\n","  print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r7K8kfQMmHdM","executionInfo":{"status":"ok","timestamp":1658413022951,"user_tz":-120,"elapsed":1196,"user":{"displayName":"Ji Lan","userId":"06508059979673879762"}},"outputId":"97946bb6-3778-4f67-fcdc-24478026824f"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy of the model on the 10000 test images: 98.97000122070312 %\n"]}]}]}