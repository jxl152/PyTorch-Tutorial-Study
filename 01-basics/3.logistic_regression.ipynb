{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"logistic_regression.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN5zMBJ0F3CmINzS2BFTTLw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"8vheawvlR87X","executionInfo":{"status":"ok","timestamp":1658336301585,"user_tz":-120,"elapsed":2687,"user":{"displayName":"Ji Lan","userId":"06508059979673879762"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms"]},{"cell_type":"markdown","source":["# 1. Hyper-parameters and Dataset"],"metadata":{"id":"gJs9hOjyiwxx"}},{"cell_type":"code","source":["# Hyper-parameters \n","input_size = 28 * 28\n","num_classes = 10\n","num_epochs = 5\n","batch_size = 100\n","learning_rate = 0.001"],"metadata":{"id":"pBKWk3oXSpbv","executionInfo":{"status":"ok","timestamp":1658336298902,"user_tz":-120,"elapsed":5,"user":{"displayName":"Ji Lan","userId":"06508059979673879762"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t-L28Q4WS9K-","executionInfo":{"status":"ok","timestamp":1658336319133,"user_tz":-120,"elapsed":17561,"user":{"displayName":"Ji Lan","userId":"06508059979673879762"}},"outputId":"249243cc-0141-4801-fa0a-ba8f62eeeeaa"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["data_dir = '/content/drive/My Drive/PyTorch/Github_Series/01-basics/'\n","\n","# MNIST dataset (images and labels)\n","train_dataset = torchvision.datasets.MNIST(root=data_dir, \n","                                           train=True, \n","                                           download=True, \n","                                           transform=transforms.ToTensor())\n","\n","test_dataset = torchvision.datasets.MNIST(root=data_dir,\n","                                          train=False,\n","                                          transform=transforms.ToTensor())\n","\n","# Data loader (input pipeline)\n","train_loader = torch.utils.data.DataLoader(train_dataset,\n","                                           batch_size=batch_size,\n","                                           shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(test_dataset,\n","                                          batch_size=batch_size,\n","                                          shuffle=True)"],"metadata":{"id":"hD4Q4mNLTJ0P","executionInfo":{"status":"ok","timestamp":1658336358638,"user_tz":-120,"elapsed":2624,"user":{"displayName":"Ji Lan","userId":"06508059979673879762"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# 2. Train the Logistic Regression model"],"metadata":{"id":"vKZpMwrnjOcL"}},{"cell_type":"code","source":["# Logistic regression model\n","model = nn.Linear(input_size, num_classes)\n","\n","# Loss and optimizer\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","\n","# Train the model\n","total_step = len(train_loader)\n","for epoch in range(num_epochs):\n","  for batch_index, (images, labels) in enumerate(train_loader):\n","    # Reshape images to (batch_size, input_size)\n","    images = images.reshape(-1, input_size)                                                                                                                                                                                                                                   \n","    \n","    # Forward pass\n","    pred = model(images)\n","    loss = loss_fn(pred, labels)\n","    \n","    # Backward and optimize\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if (batch_index + 1) % 100 == 0:\n","      print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n","            .format(epoch+1, num_epochs, batch_index+1, total_step, loss.item()))"],"metadata":{"id":"J4xYL0wNTjw4","executionInfo":{"status":"ok","timestamp":1658336807063,"user_tz":-120,"elapsed":29535,"user":{"displayName":"Ji Lan","userId":"06508059979673879762"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"26953c1e-57f4-48bf-e07a-c83b319bf5b5"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/5], Step [100/600], Loss: 2.2048\n","Epoch [1/5], Step [200/600], Loss: 2.0892\n","Epoch [1/5], Step [300/600], Loss: 2.0102\n","Epoch [1/5], Step [400/600], Loss: 1.9231\n","Epoch [1/5], Step [500/600], Loss: 1.8715\n","Epoch [1/5], Step [600/600], Loss: 1.7348\n","Epoch [2/5], Step [100/600], Loss: 1.7467\n","Epoch [2/5], Step [200/600], Loss: 1.7069\n","Epoch [2/5], Step [300/600], Loss: 1.6302\n","Epoch [2/5], Step [400/600], Loss: 1.5556\n","Epoch [2/5], Step [500/600], Loss: 1.4872\n","Epoch [2/5], Step [600/600], Loss: 1.4216\n","Epoch [3/5], Step [100/600], Loss: 1.3580\n","Epoch [3/5], Step [200/600], Loss: 1.3309\n","Epoch [3/5], Step [300/600], Loss: 1.3544\n","Epoch [3/5], Step [400/600], Loss: 1.3617\n","Epoch [3/5], Step [500/600], Loss: 1.2772\n","Epoch [3/5], Step [600/600], Loss: 1.2334\n","Epoch [4/5], Step [100/600], Loss: 1.2381\n","Epoch [4/5], Step [200/600], Loss: 1.0921\n","Epoch [4/5], Step [300/600], Loss: 1.1353\n","Epoch [4/5], Step [400/600], Loss: 1.1911\n","Epoch [4/5], Step [500/600], Loss: 1.2154\n","Epoch [4/5], Step [600/600], Loss: 1.1049\n","Epoch [5/5], Step [100/600], Loss: 1.1827\n","Epoch [5/5], Step [200/600], Loss: 1.1968\n","Epoch [5/5], Step [300/600], Loss: 1.1561\n","Epoch [5/5], Step [400/600], Loss: 1.0301\n","Epoch [5/5], Step [500/600], Loss: 0.9956\n","Epoch [5/5], Step [600/600], Loss: 0.9870\n"]}]},{"cell_type":"markdown","source":["# 3. Test the model"],"metadata":{"id":"5ZSaB3OSkyHq"}},{"cell_type":"code","source":["# Test the model\n","# In test phase, we don't need to compute gradients (for memory efficiency)\n","with torch.no_grad():\n","  correct = 0\n","  total = 0\n","  for images, labels in test_loader:\n","    images = images.reshape(-1, input_size)\n","    outputs = model(images)\n","    _, pred = torch.max(outputs, dim=1)   # return (max, max_indices)\n","    total += labels.size(0)\n","    correct += (pred == labels).sum()\n","\n","  print('Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RfZJHtLwcedk","executionInfo":{"status":"ok","timestamp":1658337004937,"user_tz":-120,"elapsed":1295,"user":{"displayName":"Ji Lan","userId":"06508059979673879762"}},"outputId":"568b3501-5ea5-49a2-92ea-464cbd2b73f2"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the model on the 10000 test images: 82.4800033569336 %\n"]}]}]}