{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"feedforward_neural_network.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyON9+mBDNbIH2cp7W7/+Kar"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"tlo2BHMeidw1"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms"]},{"cell_type":"markdown","source":["# 1. Hyper-parameters and Dataset\n","\n","**Image preprocessing**: converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]."],"metadata":{"id":"yOPeSuz3o-Sm"}},{"cell_type":"code","source":["# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Hyper-parameters \n","input_size = 784\n","hidden_size = 500\n","num_classes = 10\n","num_epochs = 5\n","batch_size = 100\n","learning_rate = 0.001"],"metadata":{"id":"lK-bztf1F_Gk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KNhM1qHpH6Nt","executionInfo":{"status":"ok","timestamp":1658339162530,"user_tz":-120,"elapsed":2680,"user":{"displayName":"Ji Lan","userId":"06508059979673879762"}},"outputId":"2e0e3145-9070-4d43-a38b-0ce3be84fd37"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["data_dir = '/content/drive/My Drive/PyTorch/Github_Series/01-basics/'\n","\n","# MNIST dataset\n","train_dataset = torchvision.datasets.MNIST(root=data_dir,\n","                                           train=True,\n","                                           transform=transforms.ToTensor(),\n","                                           download=True)\n","\n","test_dataset = torchvision.datasets.MNIST(root=data_dir,\n","                                          train=False,\n","                                          transform=transforms.ToTensor(),\n","                                          download=True)\n","\n","# MNIST dataset loader\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size,\n","                                           shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size,\n","                                          shuffle=True)"],"metadata":{"id":"R9VRtUbCGBrj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. Modeling and Training"],"metadata":{"id":"RassD1dVpNRF"}},{"cell_type":"code","source":["# Fully connected neural network with one hidden layer\n","class NeuralNet(nn.Module):\n","  \n","  def __init__(self, input_size, hidden_size, num_classes):\n","    super().__init__()\n","    self.fc1 = nn.Linear(input_size, hidden_size)\n","    self.relu = nn.ReLU()\n","    self.fc2 = nn.Linear(hidden_size, num_classes)\n","\n","  def forward(self, x):\n","    out = self.fc1(x)\n","    out = self.relu(out)\n","    out = self.fc2(out)\n","    return out"],"metadata":{"id":"3AKkMsF9IpPU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize the model\n","model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n","\n","# Loss and optimizer\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Train the model\n","total_step = len(train_loader)\n","for epoch in range(num_epochs):\n","  for batch_index, (images, labels) in enumerate(train_loader):\n","    # Reshpae into (batch_size, input_size)\n","    input = images.reshape(-1, input_size).to(device)   # It is necessary to have both the model and the data on the same device\n","    labels = labels.to(device)\n","    # Feedforward\n","    output = model.forward(input)\n","    # Loss\n","    loss = loss_fn(output, labels)\n","    # Backward propagation\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    \n","    if (batch_index+1) % 100 == 0:\n","      print('Epoch: [{}/{}], Step: [{}/{}], Loss: {:.4f}'\n","            .format(epoch+1, num_epochs, batch_index+1, total_step, loss.item()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O8j9PCI9oKC0","executionInfo":{"status":"ok","timestamp":1658339197004,"user_tz":-120,"elapsed":34479,"user":{"displayName":"Ji Lan","userId":"06508059979673879762"}},"outputId":"2fb048c8-59af-4ea3-cabc-d84ea17846a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: [1/5], Step: [100/600], Loss: 0.2662\n","Epoch: [1/5], Step: [200/600], Loss: 0.2029\n","Epoch: [1/5], Step: [300/600], Loss: 0.3094\n","Epoch: [1/5], Step: [400/600], Loss: 0.2401\n","Epoch: [1/5], Step: [500/600], Loss: 0.0903\n","Epoch: [1/5], Step: [600/600], Loss: 0.1478\n","Epoch: [2/5], Step: [100/600], Loss: 0.1168\n","Epoch: [2/5], Step: [200/600], Loss: 0.1536\n","Epoch: [2/5], Step: [300/600], Loss: 0.0421\n","Epoch: [2/5], Step: [400/600], Loss: 0.0558\n","Epoch: [2/5], Step: [500/600], Loss: 0.1232\n","Epoch: [2/5], Step: [600/600], Loss: 0.0645\n","Epoch: [3/5], Step: [100/600], Loss: 0.0399\n","Epoch: [3/5], Step: [200/600], Loss: 0.0567\n","Epoch: [3/5], Step: [300/600], Loss: 0.0426\n","Epoch: [3/5], Step: [400/600], Loss: 0.0397\n","Epoch: [3/5], Step: [500/600], Loss: 0.0523\n","Epoch: [3/5], Step: [600/600], Loss: 0.0385\n","Epoch: [4/5], Step: [100/600], Loss: 0.0868\n","Epoch: [4/5], Step: [200/600], Loss: 0.0454\n","Epoch: [4/5], Step: [300/600], Loss: 0.0556\n","Epoch: [4/5], Step: [400/600], Loss: 0.0813\n","Epoch: [4/5], Step: [500/600], Loss: 0.0268\n","Epoch: [4/5], Step: [600/600], Loss: 0.0334\n","Epoch: [5/5], Step: [100/600], Loss: 0.0484\n","Epoch: [5/5], Step: [200/600], Loss: 0.0866\n","Epoch: [5/5], Step: [300/600], Loss: 0.0221\n","Epoch: [5/5], Step: [400/600], Loss: 0.0723\n","Epoch: [5/5], Step: [500/600], Loss: 0.0130\n","Epoch: [5/5], Step: [600/600], Loss: 0.0540\n"]}]},{"cell_type":"markdown","source":["# 3. Test the model"],"metadata":{"id":"Z4y9gmFaq4vr"}},{"cell_type":"code","source":["# Test the model\n","with torch.no_grad():\n","  correct = 0\n","  total_cnt = 0\n","  for images, labels in test_loader:\n","    input = images.reshape(-1, input_size).to(device)\n","    labels = labels.to(device)\n","    output = model.forward(input)\n","    _, pred = torch.max(output, dim=1)    # (max_value, max_index)\n","    total_cnt += labels.size(0)\n","    correct += (pred == labels).sum().item()\n","\n","  print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total_cnt))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nl0Rb93qq00I","executionInfo":{"status":"ok","timestamp":1658339198283,"user_tz":-120,"elapsed":1289,"user":{"displayName":"Ji Lan","userId":"06508059979673879762"}},"outputId":"285ed04d-a912-4e03-c224-0ae4378732cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the network on the 10000 test images: 97.71 %\n"]}]}]}