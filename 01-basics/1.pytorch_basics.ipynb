{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PyTorch_Basics.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMtNXxJSn5CKtE3oJZ279Lq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":22,"metadata":{"id":"o0EFNiJ7oGjx","executionInfo":{"status":"ok","timestamp":1658326395254,"user_tz":-120,"elapsed":328,"user":{"displayName":"Ji Lan","userId":"06508059979673879762"}}},"outputs":[],"source":["import torch \n","import torchvision\n","import torch.nn as nn\n","import numpy as np\n","import torchvision.transforms as transforms\n","from torchvision.models import resnet18, ResNet18_Weights"]},{"cell_type":"markdown","source":["# 1. Basic autograd example 1"],"metadata":{"id":"URoFmk_uoTLh"}},{"cell_type":"code","source":["# create tensors\n","x = torch.tensor(1., requires_grad=True)\n","w = torch.tensor(2., requires_grad=True)\n","b = torch.tensor(3., requires_grad=True)\n","\n","# build a computational graph\n","y = w * x + b\n","\n","# compute gradients\n","y.backward()\n","\n","# print out the gradients\n","print(x.grad)   # x.grad = 2\n","print(w.grad)   # w.grad = 1\n","print(b.grad)   # b.grad = 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oL2FLw7ZoSrS","executionInfo":{"status":"ok","timestamp":1658325530414,"user_tz":-120,"elapsed":7,"user":{"displayName":"Ji Lan","userId":"06508059979673879762"}},"outputId":"108700f7-84c6-45f4-c49a-8f557c824bbc"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(2.)\n","tensor(1.)\n","tensor(1.)\n"]}]},{"cell_type":"markdown","source":["# 2. Basic autograd example 2"],"metadata":{"id":"v9FisqPYrcne"}},{"cell_type":"code","source":["# Create tensors of shape (10, 3) and (10, 2).\n","x = torch.randn(10, 3)\n","y = torch.randn(10, 2)\n","\n","# Build a fully connected layer.\n","linear = nn.Linear(3, 2)\n","\n","# Build loss function and optimizer.\n","loss_func = nn.MSELoss()\n","optimizer = torch.optim.SGD(linear.parameters(), lr=0.01)\n","\n","# Forward pass.\n","pred = linear(x)\n","\n","# Compute loss.\n","loss = loss_func(pred, y)\n","print('loss:', loss.item())\n","\n","# Backward pass.\n","loss.backward()\n","\n","# Print out the gradients.\n","print('dL/dw:', linear.weight.grad)\n","print('dL/db:', linear.bias.grad)\n","\n","# 1-step gradient descent.\n","optimizer.step()\n","\n","# You can also perform gradient descent at the low level.\n","# linear.weight.data.sub_(0.01 * linear.weight.grad.data)\n","# linear.bias.data.sub_(0.01 * linear.bias.grad.data)\n","\n","# Print out the loss after 1-step gradient descent.\n","pred = linear(x)\n","loss = loss_func(pred, y)\n","print('loss after 1 step update:', loss.item())   # it should decrease compared to the first-time loss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YzFkmkLVqQN2","executionInfo":{"status":"ok","timestamp":1658325541782,"user_tz":-120,"elapsed":208,"user":{"displayName":"Ji Lan","userId":"06508059979673879762"}},"outputId":"7bd61c06-83ba-47dd-f71c-2f643fe98362"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["loss: 0.8465279340744019\n","dL/dw: tensor([[-0.4377,  0.3501,  0.2573],\n","        [ 0.4771,  0.2365,  0.0517]])\n","dL/db: tensor([ 0.2661, -0.1565])\n","loss after 1 step update: 0.8389414548873901\n"]}]},{"cell_type":"markdown","source":["# 3. Loading data from numpy"],"metadata":{"id":"XP9Ih5FF1EMO"}},{"cell_type":"code","source":["# Create a numpy array.\n","x = np.array([[1,2,3], [4,5,6]])\n","print(x)\n","\n","# Convert the numpy array to a torch tensor.\n","y = torch.from_numpy(x)\n","print(y)\n","\n","# Convert the torch tensor to a numpy array.\n","z = y.numpy()\n","print(z)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wS-DlhjNra93","executionInfo":{"status":"ok","timestamp":1658325725199,"user_tz":-120,"elapsed":215,"user":{"displayName":"Ji Lan","userId":"06508059979673879762"}},"outputId":"087af26a-08a2-4b1e-c600-acbc743a13d0"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1 2 3]\n"," [4 5 6]]\n","tensor([[1, 2, 3],\n","        [4, 5, 6]])\n","[[1 2 3]\n"," [4 5 6]]\n"]}]},{"cell_type":"markdown","source":["# 4. Input pipeline"],"metadata":{"id":"EZ3jVPnB3tej"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pCUNNZA0gd8U","executionInfo":{"status":"ok","timestamp":1658325809143,"user_tz":-120,"elapsed":19954,"user":{"displayName":"Ji Lan","userId":"06508059979673879762"}},"outputId":"e9605923-e188-48bc-9188-360e28da9727"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Download and construct CIFAR-10 dataset.\n","data_dir = '/content/drive/My Drive/PyTorch/Github_Series/01-basics/'\n","train_dataset = torchvision.datasets.CIFAR10(root=data_dir,\n","                                             train=True, \n","                                             transform=transforms.ToTensor(),\n","                                             download=True)\n","\n","# Fetch one data pair (read data from disk).\n","image, label = train_dataset[0]\n","print(image.size())\n","print(label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vp4xYBu5ra_1","executionInfo":{"status":"ok","timestamp":1658325874121,"user_tz":-120,"elapsed":4043,"user":{"displayName":"Ji Lan","userId":"06508059979673879762"}},"outputId":"f2a350d7-17c0-4c6e-a0ec-44761da7f339"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","torch.Size([3, 32, 32])\n","6\n"]}]},{"cell_type":"code","source":["# Data loader (this provides queues and threads in a very simple way).\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=64, \n","                                           shuffle=True)\n","\n","# When iteration starts, queue and thread start to load data from files.\n","data_iter = iter(train_loader)\n","\n","# Mini-batch images and labels.\n","images, labels = data_iter.next()\n","\n","# Actual usage of the data loader is as below.\n","for images, labels in train_loader:\n","    # Training code should be written here.\n","    pass"],"metadata":{"id":"76JdNlqm5ucx","executionInfo":{"status":"ok","timestamp":1658325823530,"user_tz":-120,"elapsed":6335,"user":{"displayName":"Ji Lan","userId":"06508059979673879762"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["# 5. Input pipeline for custom dataset"],"metadata":{"id":"QlggQLHwjieP"}},{"cell_type":"code","source":["# You should build your custom dataset as below.\n","class CustomDataset(torch.utils.data.Dataset):\n","  def __init__(self):\n","    # TODO\n","    # 1. Initialize file paths or a list of file names.\n","    pass\n","  def __getitem__(self, index):\n","    # TODO\n","    # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open)\n","    # 2. Preprocess the data (e.g. torchvision.Transform)\n","    # 3. Return a data pair (e.g. image and label)\n","    pass\n","  def __len__(self):\n","    # TODO\n","    # 1. Return the toal size of your dataset\n","    return 1\n","\n","# You can then use the prebuilt data loader. \n","custom_dataset = CustomDataset()\n","train_loader = torch.utils.data.DataLoader(dataset=custom_dataset,\n","                                           batch_size=64, \n","                                           shuffle=True)"],"metadata":{"id":"djrQedu_5ufY","executionInfo":{"status":"ok","timestamp":1658325966248,"user_tz":-120,"elapsed":200,"user":{"displayName":"Ji Lan","userId":"06508059979673879762"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["# 6. Pretrained model"],"metadata":{"id":"4UE9q014bNmF"}},{"cell_type":"code","source":["# Download and load the pretrained ResNet-18.\n","resnet18 = torchvision.models.resnet18(weights=ResNet18_Weights.DEFAULT)    # PyTorch v1.5+\n","\n","# If you want to finetune only the top layer of the model, set as below.\n","for param in resnet18.parameters():\n","  param.requires_grad = False\n","\n","# Display all model layer weights\n","# for name, para in resnet18.named_parameters():\n","#     print('{}: {}'.format(name, para.shape))\n","\n","# Replace the top layer for finetuning.\n","resnet18.fc = nn.Linear(resnet18.fc.in_features, 100)  # 100 is an example.\n","\n","# Forward pass.\n","images = torch.randn(64, 3, 224, 224)     \n","output = resnet18(images)\n","print(output.size())    # (64, 100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NnM7AKeWWwlH","executionInfo":{"status":"ok","timestamp":1658326702362,"user_tz":-120,"elapsed":5763,"user":{"displayName":"Ji Lan","userId":"06508059979673879762"}},"outputId":"a5542f54-d503-409e-850d-c8ea14f15eb8"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([64, 100])\n"]}]},{"cell_type":"markdown","source":["# 7. Save and load the model  "],"metadata":{"id":"jtjCC9s-oT16"}},{"cell_type":"code","source":["# Save and load the entire model.\n","torch.save(resnet18, data_dir + 'models/resnet18.ckpt')\n","resnet18 = torch.load(data_dir + 'models/resnet18.ckpt')\n","\n","# Save and load only the model parameters (recommended).\n","torch.save(resnet18.state_dict(), data_dir + 'models/params.ckpt')\n","resnet18.load_state_dict(torch.load(data_dir + 'models/params.ckpt'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pRNp2LPOoY0A","executionInfo":{"status":"ok","timestamp":1658326656721,"user_tz":-120,"elapsed":2122,"user":{"displayName":"Ji Lan","userId":"06508059979673879762"}},"outputId":"71e4ec65-a840-4fd4-ac18-f9f10a2058d9"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":28}]}]}